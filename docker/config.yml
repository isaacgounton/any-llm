# Configuration for any-llm-gateway

# Database connection URL
database_url: "postgresql://gateway:gateway@postgres:5432/gateway"

# Server configuration - if you want to use a different port, change it here and in the docker-compose.yml file.
host: "0.0.0.0"
port: 8000

# Master key for protecting key management endpoints
master_key: ${GATEWAY_MASTER_KEY}

# Pre-configured provider credentials
providers:
  vertexai:
    # Vertex AI is a unique case in that it requires a service account JSON file, project ID, and location. See src/any_llm/gateway/auth/vertex_auth.py for more details.
    credentials: "/app/service_account.json" # Internal docker path as mapped in docker-compose.yml,
    project: ${GOOGLE_CLOUD_PROJECT}
    location: ${GOOGLE_CLOUD_LOCATION}

  openai:
    api_key: ${OPENAI_API_KEY}
    api_base: "https://api.openai.com/v1"  # optional

  anthropic:
    api_key: ${ANTHROPIC_API_KEY}

  mistral:
    api_key: ${MISTRAL_API_KEY}

  deepseek:
    api_key: ${DEEPSEEK_API_KEY}

  cohere:
    api_key: ${COHERE_API_KEY}

  groq:
    api_key: ${GROQ_API_KEY}

  together:
    api_key: ${TOGETHER_API_KEY}

  fireworks:
    api_key: ${FIREWORKS_API_KEY}

  cerebras:
    api_key: ${CEREBRAS_API_KEY}

  sambanova:
    api_key: ${SAMBANOVA_API_KEY}

  voyage:
    api_key: ${VOYAGE_API_KEY}

  portkey:
    api_key: ${PORTKEY_API_KEY}

  openrouter:
    api_key: ${OPENROUTER_API_KEY}

  perplexity:
    api_key: ${PERPLEXITY_API_KEY}

  gemini:
    api_key: ${GEMINI_API_KEY}

  azure:
    api_key: ${AZURE_OPENAI_API_KEY}

  bedrock:
    access_key: ${AWS_ACCESS_KEY_ID}
    secret_key: ${AWS_SECRET_ACCESS_KEY}
    bearer_token: ${AWS_BEARER_TOKEN_BEDROCK}

  huggingface:
    api_key: ${HF_TOKEN}

  lm_studio:
    api_key: ${LM_STUDIO_API_KEY}

  ollama:
    api_key: ${OLLAMA_API_KEY}

  llamacpp:
    api_key: ${LLAMACPP_API_KEY}

  llamafile:
    api_key: ${LLAMAFILE_API_KEY}

  databricks:
    token: ${DATABRICKS_TOKEN}

  watsonx:
    api_key: ${WATSONX_API_KEY}

  moonshot:
    api_key: ${MOONSHOT_API_KEY}

  nebius:
    api_key: ${NEBIUS_API_KEY}

  inception:
    api_key: ${INCEPTION_API_KEY}

  llama:
    api_key: ${LLAMA_API_KEY}

  minimax:
    api_key: ${MINIMAX_API_KEY}

  xai:
    api_key: ${XAI_API_KEY}

  zai:
    api_key: ${ZAI_API_KEY}

  google:
    api_key: ${GOOGLE_API_KEY}

  # Add more providers as needed...

# Model pricing configuration (optional but necessary for price tracking)
# Format: "provider:model" -> input/output price per million tokens
# Database pricing takes precedence - config only sets initial values
# Prices are in USD per million tokens
pricing:
  # See https://cloud.google.com/vertex-ai/generative-ai/pricing
  # vertexai:Qwen3-235B-A22B-Instruct-2507:
  #   input_price_per_million: 0.25
  #   output_price_per_million: 1.00
  # openai:gpt-5:
    # input_price_per_million: 0.25
    # output_price_per_million: 1.00
